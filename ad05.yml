train:
  dev_directory: ./dev_data
  feature:
      frames: 5
      hop_length: 512
      n_fft: 1024
      n_mels: 128
      power: 2.0
      downsample: True
  fit:
      batch_size: 512
      compile:
        loss: mean_squared_error
        optimizer: adam
      epochs: 100
      shuffle: true
      validation_split: 0.1
      verbose: 1
  max_fpr: 0.1
  model:
      input_dim: 96
      batch_norm: true
      latent_dim: 8
      hidden_dim: 64
      l1reg: 0
      name: keras_model
      encode_depth: 2
      encode_in: 64
      decode_depth: 2
      decode_out: 64
      quantization:
          bits: 12
          int_bits: 0
          last_bits: 12
          last_int_bits: 0
          relu_bits: 6
          relu_int_bits: 6
  pruning:
      constant: false
      decay: false
      final_step: None
      initial_step: 0
      power: None
      sparsity: None
      initial_sparsity: None
      final_sparsity: None
  model_directory: ./model/model_config/96input_depth2_x64_12b
  result_directory: ./result/test/model_config/96input_depth2_x64_12b
  result_file: result.csv
convert:
  x_npy_plot_roc: test_data/anomaly_detection/evaluation/downsampled_128_5_to_32_3_skip_method.npy
  y_npy_plot_roc: test_data/anomaly_detection/evaluation/downsampled_128_5_to_32_3_ground_truths_skip_method.npy
  x_npy_hls_test_bench: ./test_data/anomaly_detection/test_bench/downsampled_128_5_to_32_3_skip_method.npy
  y_npy_hls_test_bench: ./test_data/anomaly_detection/test_bench/downsampled_128_5_to_32_3_ground_truths_skip_method.npy
  model_file: model/ad05/model_ToyCar.h5
  Build: True
  OutputDir: hls/model/ad05_fifo_opts/
  ClockPeriod: 10
  vivado_path: "/tools/Xilinx/Vivado/2019.1/bin:"
  Board: pynq-z2
  Trace: 0
  fpga_part: xc7z020clg400-1
  acc_name: anomaly_detection
  Backend: VivadoAccelerator
  IOType: io_stream
  Interface: axi_stream
  Driver: python
  Strategy: Resource
  HLSConfig:
    LayerName:
      batch_normalization:
        Precision:
          bias: ap_fixed<13,8>
          scale: ap_fixed<13,6>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      batch_normalization_1:
        Precision:
          bias: ap_fixed<16,6>
          scale: ap_fixed<16,6>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<27,16>
      batch_normalization_2:
        Precision:
          bias: ap_fixed<10,6>
          scale: ap_fixed<10,6>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      batch_normalization_3:
        Precision:
          bias: ap_fixed<16,6>
          scale: ap_fixed<16,6>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      batch_normalization_4:
        Precision:
          bias: ap_fixed<12,6>
          scale: ap_fixed<12,6>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      input_1:
        Precision: ap_fixed<8,8>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_activation:
        Precision:
          result: ap_fixed<7,7>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<28,16>
      q_activation_1:
        Precision:
          result: ap_fixed<7,7>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_activation_2:
        Precision:
          result: ap_fixed<7,7>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_activation_3:
        Precision:
          result: ap_fixed<7,7>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_activation_4:
        Precision:
          result: ap_fixed<7,7>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_dense:
        Precision:
          bias: ap_fixed<13,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<27,16>
      q_dense_1:
        Precision:
          bias: ap_fixed<13,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_dense_2:
        Precision:
          bias: ap_fixed<13,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_dense_3:
        Precision:
          bias: ap_fixed<13,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_dense_4:
        Precision:
          bias: ap_fixed<13,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
      q_dense_5:
        Precision:
          bias: ap_fixed<4,1>
          weight: ap_fixed<13,1>
        ReuseFactor: 4096
        Trace: true
        accum_t: ap_fixed<24,16>
    Model:
      Precision: ap_fixed<24,16>
      ReuseFactor: 4096
      Strategy: Resource
      FIFO_opt: True